WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.570 align:start position:0%
 
pie<00:00:00.599><c> torch</c><00:00:01.020><c> an</c><00:00:01.319><c> open</c><00:00:01.500><c> source</c><00:00:01.979><c> deep</c><00:00:02.159><c> learning</c>

00:00:02.570 --> 00:00:02.580 align:start position:0%
pie torch an open source deep learning
 

00:00:02.580 --> 00:00:04.249 align:start position:0%
pie torch an open source deep learning
framework<00:00:02.940><c> used</c><00:00:03.300><c> to</c><00:00:03.540><c> build</c><00:00:03.659><c> some</c><00:00:03.959><c> of</c><00:00:04.080><c> the</c>

00:00:04.249 --> 00:00:04.259 align:start position:0%
framework used to build some of the
 

00:00:04.259 --> 00:00:05.570 align:start position:0%
framework used to build some of the
world's<00:00:04.500><c> most</c><00:00:04.740><c> famous</c><00:00:04.920><c> artificial</c>

00:00:05.570 --> 00:00:05.580 align:start position:0%
world's most famous artificial
 

00:00:05.580 --> 00:00:07.670 align:start position:0%
world's most famous artificial
intelligence<00:00:06.180><c> products</c><00:00:06.660><c> it</c><00:00:07.020><c> was</c><00:00:07.140><c> created</c><00:00:07.500><c> at</c>

00:00:07.670 --> 00:00:07.680 align:start position:0%
intelligence products it was created at
 

00:00:07.680 --> 00:00:10.370 align:start position:0%
intelligence products it was created at
The<00:00:07.799><c> Meta</c><00:00:08.099><c> AI</c><00:00:08.340><c> research</c><00:00:08.760><c> lab</c><00:00:08.940><c> in</c><00:00:09.179><c> 2016</c><00:00:09.660><c> but</c><00:00:10.139><c> is</c>

00:00:10.370 --> 00:00:10.380 align:start position:0%
The Meta AI research lab in 2016 but is
 

00:00:10.380 --> 00:00:12.110 align:start position:0%
The Meta AI research lab in 2016 but is
actually<00:00:10.559><c> derived</c><00:00:11.099><c> from</c><00:00:11.280><c> the</c><00:00:11.460><c> Lua</c><00:00:11.820><c> based</c>

00:00:12.110 --> 00:00:12.120 align:start position:0%
actually derived from the Lua based
 

00:00:12.120 --> 00:00:14.570 align:start position:0%
actually derived from the Lua based
torch<00:00:12.420><c> library</c><00:00:12.599><c> that</c><00:00:13.019><c> dates</c><00:00:13.259><c> back</c><00:00:13.440><c> to</c><00:00:13.679><c> 2002.</c>

00:00:14.570 --> 00:00:14.580 align:start position:0%
torch library that dates back to 2002.
 

00:00:14.580 --> 00:00:16.369 align:start position:0%
torch library that dates back to 2002.
fundamentally<00:00:15.120><c> it's</c><00:00:15.480><c> a</c><00:00:15.660><c> library</c><00:00:15.900><c> for</c>

00:00:16.369 --> 00:00:16.379 align:start position:0%
fundamentally it's a library for
 

00:00:16.379 --> 00:00:18.050 align:start position:0%
fundamentally it's a library for
programming<00:00:16.859><c> with</c><00:00:17.100><c> tensors</c><00:00:17.520><c> which</c><00:00:17.880><c> are</c>

00:00:18.050 --> 00:00:18.060 align:start position:0%
programming with tensors which are
 

00:00:18.060 --> 00:00:19.790 align:start position:0%
programming with tensors which are
basically<00:00:18.359><c> just</c><00:00:18.600><c> multi-dimensional</c><00:00:19.380><c> arrays</c>

00:00:19.790 --> 00:00:19.800 align:start position:0%
basically just multi-dimensional arrays
 

00:00:19.800 --> 00:00:22.070 align:start position:0%
basically just multi-dimensional arrays
that<00:00:20.039><c> represent</c><00:00:20.460><c> data</c><00:00:20.939><c> and</c><00:00:21.060><c> parameters</c><00:00:21.660><c> in</c>

00:00:22.070 --> 00:00:22.080 align:start position:0%
that represent data and parameters in
 

00:00:22.080 --> 00:00:23.870 align:start position:0%
that represent data and parameters in
deep<00:00:22.260><c> neural</c><00:00:22.619><c> networks</c><00:00:23.039><c> sounds</c><00:00:23.340><c> complicated</c>

00:00:23.870 --> 00:00:23.880 align:start position:0%
deep neural networks sounds complicated
 

00:00:23.880 --> 00:00:25.730 align:start position:0%
deep neural networks sounds complicated
but<00:00:24.180><c> its</c><00:00:24.480><c> focused</c><00:00:24.720><c> on</c><00:00:24.840><c> usability</c><00:00:25.320><c> will</c><00:00:25.619><c> have</c>

00:00:25.730 --> 00:00:25.740 align:start position:0%
but its focused on usability will have
 

00:00:25.740 --> 00:00:27.170 align:start position:0%
but its focused on usability will have
you<00:00:25.859><c> training</c><00:00:26.279><c> machine</c><00:00:26.400><c> learning</c><00:00:26.820><c> models</c>

00:00:27.170 --> 00:00:27.180 align:start position:0%
you training machine learning models
 

00:00:27.180 --> 00:00:28.970 align:start position:0%
you training machine learning models
with<00:00:27.420><c> just</c><00:00:27.599><c> a</c><00:00:27.720><c> few</c><00:00:27.900><c> lines</c><00:00:28.199><c> of</c><00:00:28.320><c> python</c><00:00:28.680><c> in</c>

00:00:28.970 --> 00:00:28.980 align:start position:0%
with just a few lines of python in
 

00:00:28.980 --> 00:00:30.769 align:start position:0%
with just a few lines of python in
addition<00:00:29.160><c> it</c><00:00:29.519><c> facilitates</c><00:00:30.060><c> high</c><00:00:30.359><c> performance</c>

00:00:30.769 --> 00:00:30.779 align:start position:0%
addition it facilitates high performance
 

00:00:30.779 --> 00:00:33.110 align:start position:0%
addition it facilitates high performance
parallel<00:00:31.260><c> Computing</c><00:00:31.679><c> on</c><00:00:31.920><c> a</c><00:00:32.040><c> GPU</c><00:00:32.520><c> thanks</c><00:00:32.940><c> to</c>

00:00:33.110 --> 00:00:33.120 align:start position:0%
parallel Computing on a GPU thanks to
 

00:00:33.120 --> 00:00:35.510 align:start position:0%
parallel Computing on a GPU thanks to
nvidia's<00:00:33.899><c> Cuda</c><00:00:34.320><c> platform</c><00:00:34.620><c> developers</c><00:00:35.280><c> love</c>

00:00:35.510 --> 00:00:35.520 align:start position:0%
nvidia's Cuda platform developers love
 

00:00:35.520 --> 00:00:37.370 align:start position:0%
nvidia's Cuda platform developers love
prototyping<00:00:36.180><c> with</c><00:00:36.300><c> it</c><00:00:36.480><c> because</c><00:00:36.660><c> it</c><00:00:36.960><c> supports</c>

00:00:37.370 --> 00:00:37.380 align:start position:0%
prototyping with it because it supports
 

00:00:37.380 --> 00:00:39.410 align:start position:0%
prototyping with it because it supports
a<00:00:37.620><c> dynamic</c><00:00:38.040><c> computational</c><00:00:38.579><c> graph</c><00:00:39.000><c> allowing</c>

00:00:39.410 --> 00:00:39.420 align:start position:0%
a dynamic computational graph allowing
 

00:00:39.420 --> 00:00:41.450 align:start position:0%
a dynamic computational graph allowing
models<00:00:39.840><c> to</c><00:00:39.960><c> be</c><00:00:40.079><c> optimized</c><00:00:40.620><c> at</c><00:00:40.739><c> runtime</c><00:00:41.100><c> it</c>

00:00:41.450 --> 00:00:41.460 align:start position:0%
models to be optimized at runtime it
 

00:00:41.460 --> 00:00:43.430 align:start position:0%
models to be optimized at runtime it
does<00:00:41.640><c> this</c><00:00:41.760><c> by</c><00:00:42.120><c> constructing</c><00:00:42.660><c> a</c><00:00:42.960><c> directed</c>

00:00:43.430 --> 00:00:43.440 align:start position:0%
does this by constructing a directed
 

00:00:43.440 --> 00:00:45.650 align:start position:0%
does this by constructing a directed
acyclic<00:00:44.100><c> graph</c><00:00:44.460><c> consisting</c><00:00:45.000><c> of</c><00:00:45.120><c> functions</c>

00:00:45.650 --> 00:00:45.660 align:start position:0%
acyclic graph consisting of functions
 

00:00:45.660 --> 00:00:47.270 align:start position:0%
acyclic graph consisting of functions
that<00:00:45.899><c> keeps</c><00:00:46.200><c> track</c><00:00:46.320><c> of</c><00:00:46.500><c> all</c><00:00:46.680><c> the</c><00:00:46.800><c> executed</c>

00:00:47.270 --> 00:00:47.280 align:start position:0%
that keeps track of all the executed
 

00:00:47.280 --> 00:00:49.069 align:start position:0%
that keeps track of all the executed
operations<00:00:47.760><c> on</c><00:00:48.059><c> the</c><00:00:48.180><c> tensors</c><00:00:48.539><c> allowing</c><00:00:49.020><c> you</c>

00:00:49.069 --> 00:00:49.079 align:start position:0%
operations on the tensors allowing you
 

00:00:49.079 --> 00:00:50.930 align:start position:0%
operations on the tensors allowing you
to<00:00:49.260><c> change</c><00:00:49.379><c> the</c><00:00:49.620><c> shape</c><00:00:49.860><c> size</c><00:00:50.160><c> and</c><00:00:50.460><c> operations</c>

00:00:50.930 --> 00:00:50.940 align:start position:0%
to change the shape size and operations
 

00:00:50.940 --> 00:00:53.330 align:start position:0%
to change the shape size and operations
after<00:00:51.420><c> every</c><00:00:51.780><c> iteration</c><00:00:52.260><c> if</c><00:00:52.559><c> needed</c><00:00:52.800><c> pytorch</c>

00:00:53.330 --> 00:00:53.340 align:start position:0%
after every iteration if needed pytorch
 

00:00:53.340 --> 00:00:54.650 align:start position:0%
after every iteration if needed pytorch
has<00:00:53.460><c> been</c><00:00:53.579><c> used</c><00:00:53.700><c> to</c><00:00:53.879><c> train</c><00:00:54.000><c> models</c><00:00:54.480><c> for</c>

00:00:54.650 --> 00:00:54.660 align:start position:0%
has been used to train models for
 

00:00:54.660 --> 00:00:57.049 align:start position:0%
has been used to train models for
computer<00:00:54.960><c> vision</c><00:00:55.320><c> AI</c><00:00:55.739><c> like</c><00:00:55.980><c> Tesla</c><00:00:56.460><c> autopilot</c>

00:00:57.049 --> 00:00:57.059 align:start position:0%
computer vision AI like Tesla autopilot
 

00:00:57.059 --> 00:00:59.029 align:start position:0%
computer vision AI like Tesla autopilot
image<00:00:57.480><c> generators</c><00:00:57.840><c> like</c><00:00:58.079><c> stable</c><00:00:58.440><c> diffusion</c>

00:00:59.029 --> 00:00:59.039 align:start position:0%
image generators like stable diffusion
 

00:00:59.039 --> 00:01:01.130 align:start position:0%
image generators like stable diffusion
and<00:00:59.399><c> speech</c><00:00:59.699><c> recognition</c><00:01:00.000><c> models</c><00:01:00.780><c> like</c><00:01:00.960><c> open</c>

00:01:01.130 --> 00:01:01.140 align:start position:0%
and speech recognition models like open
 

00:01:01.140 --> 00:01:03.170 align:start position:0%
and speech recognition models like open
AI<00:01:01.559><c> whisper</c><00:01:01.920><c> just</c><00:01:02.219><c> to</c><00:01:02.340><c> name</c><00:01:02.460><c> a</c><00:01:02.640><c> few</c><00:01:02.699><c> to</c><00:01:03.000><c> get</c>

00:01:03.170 --> 00:01:03.180 align:start position:0%
AI whisper just to name a few to get
 

00:01:03.180 --> 00:01:05.149 align:start position:0%
AI whisper just to name a few to get
started<00:01:03.539><c> install</c><00:01:03.840><c> Pi</c><00:01:04.260><c> torque</c><00:01:04.619><c> and</c><00:01:04.799><c> optionally</c>

00:01:05.149 --> 00:01:05.159 align:start position:0%
started install Pi torque and optionally
 

00:01:05.159 --> 00:01:07.190 align:start position:0%
started install Pi torque and optionally
Cuda<00:01:05.700><c> if</c><00:01:05.939><c> you</c><00:01:06.060><c> want</c><00:01:06.180><c> to</c><00:01:06.360><c> accelerate</c><00:01:06.780><c> Computing</c>

00:01:07.190 --> 00:01:07.200 align:start position:0%
Cuda if you want to accelerate Computing
 

00:01:07.200 --> 00:01:09.649 align:start position:0%
Cuda if you want to accelerate Computing
on<00:01:07.380><c> your</c><00:01:07.560><c> GPU</c><00:01:07.979><c> now</c><00:01:08.400><c> import</c><00:01:08.640><c> it</c><00:01:08.939><c> into</c><00:01:09.060><c> a</c><00:01:09.299><c> python</c>

00:01:09.649 --> 00:01:09.659 align:start position:0%
on your GPU now import it into a python
 

00:01:09.659 --> 00:01:11.810 align:start position:0%
on your GPU now import it into a python
file<00:01:09.960><c> or</c><00:01:10.140><c> notebook</c><00:01:10.560><c> like</c><00:01:10.979><c> I</c><00:01:11.159><c> mentioned</c><00:01:11.460><c> a</c>

00:01:11.810 --> 00:01:11.820 align:start position:0%
file or notebook like I mentioned a
 

00:01:11.820 --> 00:01:13.609 align:start position:0%
file or notebook like I mentioned a
tensor<00:01:12.180><c> is</c><00:01:12.360><c> similar</c><00:01:12.600><c> to</c><00:01:12.720><c> a</c><00:01:12.960><c> multi-dimensional</c>

00:01:13.609 --> 00:01:13.619 align:start position:0%
tensor is similar to a multi-dimensional
 

00:01:13.619 --> 00:01:15.770 align:start position:0%
tensor is similar to a multi-dimensional
array<00:01:13.920><c> create</c><00:01:14.100><c> a</c><00:01:14.340><c> 2d</c><00:01:14.580><c> array</c><00:01:15.000><c> or</c><00:01:15.180><c> Matrix</c><00:01:15.600><c> with</c>

00:01:15.770 --> 00:01:15.780 align:start position:0%
array create a 2d array or Matrix with
 

00:01:15.780 --> 00:01:17.870 align:start position:0%
array create a 2d array or Matrix with
python<00:01:16.260><c> then</c><00:01:16.500><c> use</c><00:01:16.680><c> torch</c><00:01:17.040><c> to</c><00:01:17.280><c> convert</c><00:01:17.640><c> it</c><00:01:17.700><c> into</c>

00:01:17.870 --> 00:01:17.880 align:start position:0%
python then use torch to convert it into
 

00:01:17.880 --> 00:01:19.789 align:start position:0%
python then use torch to convert it into
a<00:01:18.119><c> tensor</c><00:01:18.479><c> now</c><00:01:18.780><c> we</c><00:01:18.960><c> can</c><00:01:19.080><c> run</c><00:01:19.260><c> all</c><00:01:19.500><c> kinds</c><00:01:19.740><c> of</c>

00:01:19.789 --> 00:01:19.799 align:start position:0%
a tensor now we can run all kinds of
 

00:01:19.799 --> 00:01:21.770 align:start position:0%
a tensor now we can run all kinds of
computations<00:01:20.340><c> on</c><00:01:20.700><c> it</c><00:01:20.820><c> like</c><00:01:21.119><c> we</c><00:01:21.299><c> might</c><00:01:21.420><c> convert</c>

00:01:21.770 --> 00:01:21.780 align:start position:0%
computations on it like we might convert
 

00:01:21.780 --> 00:01:23.690 align:start position:0%
computations on it like we might convert
all<00:01:21.960><c> these</c><00:01:22.140><c> integers</c><00:01:22.560><c> into</c><00:01:22.920><c> random</c><00:01:23.400><c> floating</c>

00:01:23.690 --> 00:01:23.700 align:start position:0%
all these integers into random floating
 

00:01:23.700 --> 00:01:25.490 align:start position:0%
all these integers into random floating
points<00:01:24.060><c> we</c><00:01:24.360><c> can</c><00:01:24.540><c> also</c><00:01:24.780><c> perform</c><00:01:24.960><c> linear</c>

00:01:25.490 --> 00:01:25.500 align:start position:0%
points we can also perform linear
 

00:01:25.500 --> 00:01:27.890 align:start position:0%
points we can also perform linear
algebra<00:01:26.040><c> by</c><00:01:26.400><c> taking</c><00:01:26.580><c> multiple</c><00:01:27.119><c> tensors</c><00:01:27.540><c> and</c>

00:01:27.890 --> 00:01:27.900 align:start position:0%
algebra by taking multiple tensors and
 

00:01:27.900 --> 00:01:29.690 align:start position:0%
algebra by taking multiple tensors and
multiplying<00:01:28.500><c> them</c><00:01:28.619><c> together</c><00:01:28.860><c> what</c><00:01:29.460><c> you</c><00:01:29.580><c> came</c>

00:01:29.690 --> 00:01:29.700 align:start position:0%
multiplying them together what you came
 

00:01:29.700 --> 00:01:31.609 align:start position:0%
multiplying them together what you came
here<00:01:29.880><c> to</c><00:01:30.000><c> do</c><00:01:30.119><c> though</c><00:01:30.299><c> is</c><00:01:30.540><c> build</c><00:01:30.780><c> a</c><00:01:31.080><c> deep</c><00:01:31.200><c> neural</c>

00:01:31.609 --> 00:01:31.619 align:start position:0%
here to do though is build a deep neural
 

00:01:31.619 --> 00:01:33.710 align:start position:0%
here to do though is build a deep neural
network<00:01:31.799><c> like</c><00:01:32.340><c> an</c><00:01:32.640><c> image</c><00:01:32.880><c> classifier</c><00:01:33.360><c> to</c>

00:01:33.710 --> 00:01:33.720 align:start position:0%
network like an image classifier to
 

00:01:33.720 --> 00:01:35.510 align:start position:0%
network like an image classifier to
handle<00:01:34.020><c> that</c><00:01:34.200><c> we</c><00:01:34.439><c> can</c><00:01:34.560><c> define</c><00:01:34.740><c> a</c><00:01:35.100><c> new</c><00:01:35.280><c> class</c>

00:01:35.510 --> 00:01:35.520 align:start position:0%
handle that we can define a new class
 

00:01:35.520 --> 00:01:37.069 align:start position:0%
handle that we can define a new class
that<00:01:35.820><c> inherits</c><00:01:36.360><c> from</c><00:01:36.479><c> the</c><00:01:36.659><c> neural</c><00:01:36.960><c> network</c>

00:01:37.069 --> 00:01:37.079 align:start position:0%
that inherits from the neural network
 

00:01:37.079 --> 00:01:39.530 align:start position:0%
that inherits from the neural network
module<00:01:37.799><c> class</c><00:01:38.040><c> inside</c><00:01:38.520><c> the</c><00:01:38.820><c> Constructor</c><00:01:39.180><c> we</c>

00:01:39.530 --> 00:01:39.540 align:start position:0%
module class inside the Constructor we
 

00:01:39.540 --> 00:01:41.210 align:start position:0%
module class inside the Constructor we
can<00:01:39.659><c> build</c><00:01:39.780><c> it</c><00:01:39.960><c> out</c><00:01:40.140><c> layer</c><00:01:40.560><c> by</c><00:01:40.680><c> layer</c><00:01:40.979><c> the</c>

00:01:41.210 --> 00:01:41.220 align:start position:0%
can build it out layer by layer the
 

00:01:41.220 --> 00:01:42.530 align:start position:0%
can build it out layer by layer the
flattened<00:01:41.640><c> layer</c><00:01:41.939><c> will</c><00:01:42.119><c> take</c><00:01:42.240><c> a</c>

00:01:42.530 --> 00:01:42.540 align:start position:0%
flattened layer will take a
 

00:01:42.540 --> 00:01:44.450 align:start position:0%
flattened layer will take a
multi-dimensional<00:01:43.259><c> input</c><00:01:43.560><c> like</c><00:01:43.920><c> an</c><00:01:44.159><c> image</c>

00:01:44.450 --> 00:01:44.460 align:start position:0%
multi-dimensional input like an image
 

00:01:44.460 --> 00:01:46.370 align:start position:0%
multi-dimensional input like an image
and<00:01:44.759><c> convert</c><00:01:45.119><c> it</c><00:01:45.180><c> to</c><00:01:45.420><c> one</c><00:01:45.600><c> dimension</c><00:01:46.079><c> from</c>

00:01:46.370 --> 00:01:46.380 align:start position:0%
and convert it to one dimension from
 

00:01:46.380 --> 00:01:48.230 align:start position:0%
and convert it to one dimension from
there<00:01:46.560><c> sequential</c><00:01:47.159><c> is</c><00:01:47.340><c> used</c><00:01:47.520><c> to</c><00:01:47.820><c> create</c><00:01:48.000><c> a</c>

00:01:48.230 --> 00:01:48.240 align:start position:0%
there sequential is used to create a
 

00:01:48.240 --> 00:01:49.850 align:start position:0%
there sequential is used to create a
container<00:01:48.540><c> of</c><00:01:48.720><c> layers</c><00:01:49.020><c> that</c><00:01:49.320><c> the</c><00:01:49.439><c> data</c><00:01:49.740><c> will</c>

00:01:49.850 --> 00:01:49.860 align:start position:0%
container of layers that the data will
 

00:01:49.860 --> 00:01:51.590 align:start position:0%
container of layers that the data will
flow<00:01:50.159><c> through</c><00:01:50.280><c> each</c><00:01:50.700><c> layer</c><00:01:51.000><c> has</c><00:01:51.180><c> multiple</c>

00:01:51.590 --> 00:01:51.600 align:start position:0%
flow through each layer has multiple
 

00:01:51.600 --> 00:01:53.389 align:start position:0%
flow through each layer has multiple
nodes<00:01:51.899><c> where</c><00:01:52.320><c> each</c><00:01:52.500><c> node</c><00:01:52.799><c> is</c><00:01:52.920><c> like</c><00:01:53.040><c> its</c><00:01:53.340><c> own</c>

00:01:53.389 --> 00:01:53.399 align:start position:0%
nodes where each node is like its own
 

00:01:53.399 --> 00:01:55.429 align:start position:0%
nodes where each node is like its own
mini<00:01:53.640><c> statistical</c><00:01:54.180><c> model</c><00:01:54.479><c> as</c><00:01:54.899><c> each</c><00:01:55.140><c> data</c>

00:01:55.429 --> 00:01:55.439 align:start position:0%
mini statistical model as each data
 

00:01:55.439 --> 00:01:56.749 align:start position:0%
mini statistical model as each data
point<00:01:55.560><c> flows</c><00:01:55.860><c> through</c><00:01:56.040><c> it</c><00:01:56.159><c> it'll</c><00:01:56.460><c> try</c><00:01:56.640><c> to</c>

00:01:56.749 --> 00:01:56.759 align:start position:0%
point flows through it it'll try to
 

00:01:56.759 --> 00:01:58.850 align:start position:0%
point flows through it it'll try to
guess<00:01:57.000><c> the</c><00:01:57.240><c> output</c><00:01:57.540><c> and</c><00:01:57.899><c> gradually</c><00:01:58.259><c> update</c><00:01:58.680><c> a</c>

00:01:58.850 --> 00:01:58.860 align:start position:0%
guess the output and gradually update a
 

00:01:58.860 --> 00:02:00.469 align:start position:0%
guess the output and gradually update a
mapping<00:01:59.159><c> of</c><00:01:59.340><c> weights</c><00:01:59.640><c> to</c><00:01:59.700><c> determine</c><00:01:59.939><c> in</c><00:02:00.360><c> the</c>

00:02:00.469 --> 00:02:00.479 align:start position:0%
mapping of weights to determine in the
 

00:02:00.479 --> 00:02:02.510 align:start position:0%
mapping of weights to determine in the
importance<00:02:00.780><c> of</c><00:02:01.020><c> a</c><00:02:01.200><c> given</c><00:02:01.439><c> variable</c><00:02:01.740><c> linear</c><00:02:02.280><c> is</c>

00:02:02.510 --> 00:02:02.520 align:start position:0%
importance of a given variable linear is
 

00:02:02.520 --> 00:02:04.190 align:start position:0%
importance of a given variable linear is
a<00:02:02.700><c> fully</c><00:02:02.880><c> connected</c><00:02:03.240><c> layer</c><00:02:03.540><c> that</c><00:02:03.840><c> takes</c><00:02:03.960><c> the</c>

00:02:04.190 --> 00:02:04.200 align:start position:0%
a fully connected layer that takes the
 

00:02:04.200 --> 00:02:06.590 align:start position:0%
a fully connected layer that takes the
flat<00:02:04.439><c> and</c><00:02:04.560><c> 28</c><00:02:04.920><c> by</c><00:02:05.100><c> 28</c><00:02:05.460><c> image</c><00:02:05.820><c> and</c><00:02:06.119><c> transforms</c>

00:02:06.590 --> 00:02:06.600 align:start position:0%
flat and 28 by 28 image and transforms
 

00:02:06.600 --> 00:02:09.229 align:start position:0%
flat and 28 by 28 image and transforms
it<00:02:06.719><c> to</c><00:02:06.899><c> an</c><00:02:07.079><c> output</c><00:02:07.320><c> of</c><00:02:07.619><c> 512.</c><00:02:08.580><c> this</c><00:02:08.819><c> layer</c><00:02:09.119><c> is</c>

00:02:09.229 --> 00:02:09.239 align:start position:0%
it to an output of 512. this layer is
 

00:02:09.239 --> 00:02:11.270 align:start position:0%
it to an output of 512. this layer is
followed<00:02:09.599><c> by</c><00:02:09.840><c> a</c><00:02:10.140><c> non-linear</c><00:02:10.679><c> activation</c>

00:02:11.270 --> 00:02:11.280 align:start position:0%
followed by a non-linear activation
 

00:02:11.280 --> 00:02:13.250 align:start position:0%
followed by a non-linear activation
function<00:02:11.700><c> when</c><00:02:12.120><c> activated</c><00:02:12.599><c> it</c><00:02:12.900><c> means</c><00:02:13.140><c> that</c>

00:02:13.250 --> 00:02:13.260 align:start position:0%
function when activated it means that
 

00:02:13.260 --> 00:02:14.990 align:start position:0%
function when activated it means that
feature<00:02:13.620><c> might</c><00:02:13.739><c> be</c><00:02:13.920><c> important</c><00:02:14.220><c> and</c><00:02:14.520><c> outputs</c>

00:02:14.990 --> 00:02:15.000 align:start position:0%
feature might be important and outputs
 

00:02:15.000 --> 00:02:16.970 align:start position:0%
feature might be important and outputs
the<00:02:15.120><c> node</c><00:02:15.360><c> otherwise</c><00:02:15.840><c> it</c><00:02:16.020><c> just</c><00:02:16.200><c> outputs</c><00:02:16.620><c> zero</c>

00:02:16.970 --> 00:02:16.980 align:start position:0%
the node otherwise it just outputs zero
 

00:02:16.980 --> 00:02:18.589 align:start position:0%
the node otherwise it just outputs zero
and<00:02:17.280><c> finally</c><00:02:17.580><c> we</c><00:02:17.819><c> finish</c><00:02:17.940><c> with</c><00:02:18.180><c> a</c><00:02:18.360><c> fully</c>

00:02:18.589 --> 00:02:18.599 align:start position:0%
and finally we finish with a fully
 

00:02:18.599 --> 00:02:19.970 align:start position:0%
and finally we finish with a fully
connected<00:02:18.959><c> layer</c><00:02:19.200><c> that</c><00:02:19.440><c> outputs</c><00:02:19.739><c> the</c><00:02:19.860><c> 10</c>

00:02:19.970 --> 00:02:19.980 align:start position:0%
connected layer that outputs the 10
 

00:02:19.980 --> 00:02:21.650 align:start position:0%
connected layer that outputs the 10
labels<00:02:20.400><c> the</c><00:02:20.580><c> model</c><00:02:20.760><c> is</c><00:02:21.000><c> trying</c><00:02:21.180><c> to</c><00:02:21.360><c> predict</c>

00:02:21.650 --> 00:02:21.660 align:start position:0%
labels the model is trying to predict
 

00:02:21.660 --> 00:02:23.630 align:start position:0%
labels the model is trying to predict
with<00:02:22.020><c> these</c><00:02:22.260><c> pieces</c><00:02:22.500><c> in</c><00:02:22.739><c> place</c><00:02:22.920><c> that</c><00:02:23.400><c> next</c>

00:02:23.630 --> 00:02:23.640 align:start position:0%
with these pieces in place that next
 

00:02:23.640 --> 00:02:25.610 align:start position:0%
with these pieces in place that next
step<00:02:23.819><c> is</c><00:02:24.060><c> to</c><00:02:24.239><c> define</c><00:02:24.360><c> a</c><00:02:24.720><c> forward</c><00:02:24.900><c> method</c><00:02:25.379><c> that</c>

00:02:25.610 --> 00:02:25.620 align:start position:0%
step is to define a forward method that
 

00:02:25.620 --> 00:02:27.229 align:start position:0%
step is to define a forward method that
describes<00:02:26.099><c> the</c><00:02:26.280><c> flow</c><00:02:26.520><c> of</c><00:02:26.640><c> data</c><00:02:26.940><c> and</c><00:02:27.120><c> now</c>

00:02:27.229 --> 00:02:27.239 align:start position:0%
describes the flow of data and now
 

00:02:27.239 --> 00:02:29.570 align:start position:0%
describes the flow of data and now
instantiate<00:02:27.840><c> the</c><00:02:28.020><c> model</c><00:02:28.080><c> to</c><00:02:28.319><c> a</c><00:02:28.500><c> GPU</c><00:02:29.040><c> and</c><00:02:29.400><c> pass</c>

00:02:29.570 --> 00:02:29.580 align:start position:0%
instantiate the model to a GPU and pass
 

00:02:29.580 --> 00:02:31.070 align:start position:0%
instantiate the model to a GPU and pass
it<00:02:29.819><c> some</c><00:02:29.940><c> input</c><00:02:30.239><c> data</c><00:02:30.599><c> this</c><00:02:30.900><c> will</c>

00:02:31.070 --> 00:02:31.080 align:start position:0%
it some input data this will
 

00:02:31.080 --> 00:02:32.690 align:start position:0%
it some input data this will
automatically<00:02:31.560><c> call</c><00:02:31.800><c> its</c><00:02:32.160><c> forward</c><00:02:32.220><c> method</c>

00:02:32.690 --> 00:02:32.700 align:start position:0%
automatically call its forward method
 

00:02:32.700 --> 00:02:33.890 align:start position:0%
automatically call its forward method
for<00:02:33.000><c> training</c><00:02:33.420><c> and</c><00:02:33.599><c> prediction</c>

00:02:33.890 --> 00:02:33.900 align:start position:0%
for training and prediction
 

00:02:33.900 --> 00:02:36.290 align:start position:0%
for training and prediction
congratulations<00:02:34.739><c> you</c><00:02:35.340><c> just</c><00:02:35.520><c> built</c><00:02:35.879><c> a</c><00:02:35.940><c> neural</c>

00:02:36.290 --> 00:02:36.300 align:start position:0%
congratulations you just built a neural
 

00:02:36.300 --> 00:02:38.150 align:start position:0%
congratulations you just built a neural
network<00:02:36.480><c> this</c><00:02:36.900><c> has</c><00:02:36.959><c> been</c><00:02:37.140><c> pytorch</c><00:02:37.800><c> in</c><00:02:37.980><c> 100</c>

00:02:38.150 --> 00:02:38.160 align:start position:0%
network this has been pytorch in 100
 

00:02:38.160 --> 00:02:40.250 align:start position:0%
network this has been pytorch in 100
seconds<00:02:38.580><c> thanks</c><00:02:39.060><c> for</c><00:02:39.239><c> watching</c><00:02:39.660><c> and</c><00:02:39.959><c> I</c><00:02:40.140><c> will</c>

00:02:40.250 --> 00:02:40.260 align:start position:0%
seconds thanks for watching and I will
 

00:02:40.260 --> 00:02:43.280 align:start position:0%
seconds thanks for watching and I will
see<00:02:40.440><c> you</c><00:02:40.560><c> in</c><00:02:40.800><c> the</c><00:02:40.920><c> next</c><00:02:41.040><c> one</c>

